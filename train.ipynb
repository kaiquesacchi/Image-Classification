{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Purpose\n",
    "Trains an Image Classification neural network model, using the classes provided.\n",
    "\n",
    "# Usage\n",
    "1. Install python3-dev and scipy with `sudo apt install python3-dev python3-scipy`.\n",
    "2. Install all dependencies with `pip install -r requirements.txt`. _(VirtualEnv usage recommended)_\n",
    "3. Create an account on [Weights & Biases](https://www.wandb.com/) and login through the terminal CLI.\n",
    "4. _(Optional)_ To enable GPU usage, install the [NVIDIA packages](https://www.tensorflow.org/install/gpu#software_requirements)\n",
    "5. Execute all the ***notebook cells***\n",
    "\n",
    "# Example of Directory Structure \n",
    "```\n",
    ".\n",
    "├── ...\n",
    "├── train.ipynb\n",
    "├── requirements.txt\n",
    "├── images_formatted\n",
    "│   ├── class_A\n",
    "│   │   ├── _image0.jpg\n",
    "│   │   ├── _image1.jpg\n",
    "│   │   └── _image2.jpg\n",
    "│   └── class_B\n",
    "│       ├── _image3.jpg\n",
    "│       ├── _image4.jpg\n",
    "│       └── _image5.jpg\n",
    "├── model\n",
    "│   ├── history.csv\n",
    "│   ├── model.h5\n",
    "│   └── model.tflite\n",
    "└── wandb\n",
    "    └── [Stores the data of all runs...]\n",
    "```\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Imports and Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# Allows dynamic GPU memory allocation, instead of using the whole memory.\n",
    "# Must be added if using a RTX series' GPU and the TF-jupyter-gpu docker.\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "source": [
    "## Definitions and Parameters\n",
    "\n",
    "The following variables must be defined:\n",
    "* `TRAIN_DATA_FOLDER`: Folder which contains the images that will be used for the training. It's the output folder of `format_images.ipynb`\n",
    "\n",
    "Training parameters:\n",
    "* `NUMBER_OF_CLASSES`: Amount of classes that should be recognized by the trained model.\n",
    "* `IMAGE_SHAPE`: A tuple composed of (width, height, channels) of the image formatting.\n",
    "* `BATCH_SIZE`: Size of each training batch. [Recommended value](https://arxiv.org/abs/1206.5533): `32`.\n",
    "* `MAX_EPOCHS`: The maximum number of training epochs. [Recommended value](https://keras.io/api/callbacks/early_stopping/): `10000` _(The training should be stopped by ***EarlyStop*** before hitting `MAX_EPOCHS`)_"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_FOLDER = \"images_formatted\"\n",
    "\n",
    "NUMBER_OF_CLASSES = 2\n",
    "IMAGE_SHAPE = (128, 128, 1)\n",
    "BATCH_SIZE = 32\n",
    "MAX_EPOCHS = 10000"
   ]
  },
  {
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset will be composed by two groups:\n",
    "* Training set (90%)\n",
    "* Validation set(10%)\n",
    "\n",
    "At each epoch, some of the images will be randomly selected and will receive distortion, zoom, rotation, shifting, mirroring and/or color inversion, in order to diversify the dataset.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 356 images belonging to 2 classes.\nFound 39 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def image_inverter(image):\n",
    "    # Has a 50% chance to invert the image, in order to diversify the dataset.\n",
    "    return 1 - image if random.choice((True, False)) else image\n",
    "\n",
    "imageDataGenerator = ImageDataGenerator(rescale=1. / 255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   rotation_range=180,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   validation_split=0.1,\n",
    "                                   preprocessing_function=image_inverter)\n",
    "\n",
    "train_generator = imageDataGenerator.flow_from_directory(TRAIN_DATA_FOLDER,\n",
    "                                                    target_size=IMAGE_SHAPE[:2],\n",
    "                                                    batch_size=BATCH_SIZE,\n",
    "                                                    color_mode='grayscale' if IMAGE_SHAPE[2] == 1 else 'rgb',\n",
    "                                                    class_mode='categorical',\n",
    "                                                    subset='training')\n",
    "\n",
    "validation_generator = imageDataGenerator.flow_from_directory(TRAIN_DATA_FOLDER,\n",
    "                                                         target_size=IMAGE_SHAPE[:2],\n",
    "                                                         batch_size=BATCH_SIZE,\n",
    "                                                         color_mode='grayscale' if IMAGE_SHAPE[2] == 1 else 'rgb',\n",
    "                                                         class_mode='categorical',\n",
    "                                                         subset='validation')"
   ]
  },
  {
   "source": [
    "## Training\n",
    "\n",
    "The model is initialized with the MobileNetV2 structure.\n",
    "\n",
    "The Adam (*Adaptive Moment Estimation*) optimization algorithm will be used in order to update iteratively the network weights during training, as it's [the most recommended](https://arxiv.org/abs/1609.04747) for image classification neural network.\n",
    "\n",
    "An Early Stop method will be used to stop the training process, monitoring the validation loss, with a ***patience*** of 300 epochs.\n",
    "\n",
    "The ***loss*** is calculated by using the ***Categorical Cross-Entropy*** method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkaiquesacchi\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n                Tracking run with wandb version 0.10.12<br/>\n                Syncing run <strong style=\"color:#cdcd00\">restful-river-24</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n                Project page: <a href=\"https://wandb.ai/kaiquesacchi/physiotherapy-platform\" target=\"_blank\">https://wandb.ai/kaiquesacchi/physiotherapy-platform</a><br/>\n                Run page: <a href=\"https://wandb.ai/kaiquesacchi/physiotherapy-platform/runs/1dfwiqm1\" target=\"_blank\">https://wandb.ai/kaiquesacchi/physiotherapy-platform/runs/1dfwiqm1</a><br/>\n                Run data is saved locally in <code>/tf/wandb/run-20210107_232438-1dfwiqm1</code><br/><br/>\n            "
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "12 [==============================] - 1s 43ms/step - loss: 0.0322 - accuracy: 0.9961 - val_loss: 0.1067 - val_accuracy: 0.9487\n",
      "Epoch 2181/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0904 - accuracy: 0.9772 - val_loss: 0.1069 - val_accuracy: 0.9487\n",
      "Epoch 2182/10000\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0709 - accuracy: 0.9699 - val_loss: 0.3422 - val_accuracy: 0.9231\n",
      "Epoch 2183/10000\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0781 - accuracy: 0.9570 - val_loss: 0.3255 - val_accuracy: 0.8974\n",
      "Epoch 2184/10000\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.0735 - accuracy: 0.9634 - val_loss: 0.2085 - val_accuracy: 0.9231\n",
      "Epoch 2185/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0622 - accuracy: 0.9807 - val_loss: 0.2363 - val_accuracy: 0.8974\n",
      "Epoch 2186/10000\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.0901 - accuracy: 0.9627 - val_loss: 0.0587 - val_accuracy: 0.9744\n",
      "Epoch 2187/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0697 - accuracy: 0.9746 - val_loss: 0.1125 - val_accuracy: 0.9231\n",
      "Epoch 2188/10000\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0983 - accuracy: 0.9568 - val_loss: 0.2480 - val_accuracy: 0.8974\n",
      "Epoch 2189/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0543 - accuracy: 0.9773 - val_loss: 0.1657 - val_accuracy: 0.9487\n",
      "Epoch 2190/10000\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0946 - accuracy: 0.9737 - val_loss: 0.1653 - val_accuracy: 0.9231\n",
      "Epoch 2191/10000\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0724 - accuracy: 0.9680 - val_loss: 0.4250 - val_accuracy: 0.8718\n",
      "Epoch 2192/10000\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.0518 - accuracy: 0.9816 - val_loss: 0.2687 - val_accuracy: 0.8974\n",
      "Epoch 2193/10000\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0814 - accuracy: 0.9667 - val_loss: 0.3222 - val_accuracy: 0.9231\n",
      "Epoch 2194/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0798 - accuracy: 0.9805 - val_loss: 0.0643 - val_accuracy: 1.0000\n",
      "Epoch 2195/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0662 - accuracy: 0.9751 - val_loss: 0.2516 - val_accuracy: 0.9487\n",
      "Epoch 2196/10000\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.0657 - accuracy: 0.9823 - val_loss: 0.5520 - val_accuracy: 0.7949\n",
      "Epoch 2197/10000\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0613 - accuracy: 0.9819 - val_loss: 0.3513 - val_accuracy: 0.8974\n",
      "Epoch 2198/10000\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.1104 - accuracy: 0.9460 - val_loss: 0.5105 - val_accuracy: 0.9231\n",
      "Epoch 2199/10000\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.1824 - accuracy: 0.9475 - val_loss: 0.3097 - val_accuracy: 0.9231\n",
      "Epoch 2200/10000\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.0627 - accuracy: 0.9818 - val_loss: 0.2965 - val_accuracy: 0.8974\n",
      "Epoch 2201/10000\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.0713 - accuracy: 0.9645 - val_loss: 0.3730 - val_accuracy: 0.8718\n",
      "Epoch 2202/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0655 - accuracy: 0.9791 - val_loss: 0.3630 - val_accuracy: 0.8205\n",
      "Epoch 2203/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.1155 - accuracy: 0.9640 - val_loss: 0.3880 - val_accuracy: 0.8718\n",
      "Epoch 2204/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0737 - accuracy: 0.9671 - val_loss: 0.5933 - val_accuracy: 0.8462\n",
      "Epoch 2205/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0488 - accuracy: 0.9780 - val_loss: 0.6638 - val_accuracy: 0.8462\n",
      "Epoch 2206/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0441 - accuracy: 0.9902 - val_loss: 0.3330 - val_accuracy: 0.8718\n",
      "Epoch 2207/10000\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.0972 - accuracy: 0.9644 - val_loss: 0.4831 - val_accuracy: 0.8718\n",
      "Epoch 2208/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.1251 - accuracy: 0.9470 - val_loss: 0.4221 - val_accuracy: 0.8718\n",
      "Epoch 2209/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0987 - accuracy: 0.9674 - val_loss: 0.3635 - val_accuracy: 0.8718\n",
      "Epoch 2210/10000\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0790 - accuracy: 0.9603 - val_loss: 0.0660 - val_accuracy: 1.0000\n",
      "Epoch 2211/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0901 - accuracy: 0.9657 - val_loss: 0.3015 - val_accuracy: 0.8974\n",
      "Epoch 2212/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0911 - accuracy: 0.9722 - val_loss: 0.2644 - val_accuracy: 0.8974\n",
      "Epoch 2213/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0980 - accuracy: 0.9660 - val_loss: 0.2154 - val_accuracy: 0.8974\n",
      "Epoch 2214/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0965 - accuracy: 0.9633 - val_loss: 0.2274 - val_accuracy: 0.8718\n",
      "Epoch 2215/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0882 - accuracy: 0.9731 - val_loss: 0.4282 - val_accuracy: 0.8974\n",
      "Epoch 2216/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0521 - accuracy: 0.9806 - val_loss: 0.5329 - val_accuracy: 0.8718\n",
      "Epoch 2217/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0387 - accuracy: 0.9914 - val_loss: 0.2599 - val_accuracy: 0.9231\n",
      "Epoch 2218/10000\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0879 - accuracy: 0.9657 - val_loss: 0.3302 - val_accuracy: 0.8974\n",
      "Epoch 2219/10000\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0762 - accuracy: 0.9552 - val_loss: 0.4908 - val_accuracy: 0.8974\n",
      "Epoch 2220/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0682 - accuracy: 0.9668 - val_loss: 0.3876 - val_accuracy: 0.9487\n",
      "Epoch 2221/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.1261 - accuracy: 0.9699 - val_loss: 0.3524 - val_accuracy: 0.8974\n",
      "Epoch 2222/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0767 - accuracy: 0.9642 - val_loss: 0.2702 - val_accuracy: 0.8974\n",
      "Epoch 2223/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0700 - accuracy: 0.9777 - val_loss: 0.6861 - val_accuracy: 0.7436\n",
      "Epoch 2224/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0545 - accuracy: 0.9787 - val_loss: 0.3416 - val_accuracy: 0.9231\n",
      "Epoch 2225/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0596 - accuracy: 0.9813 - val_loss: 0.3036 - val_accuracy: 0.8718\n",
      "Epoch 2226/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0673 - accuracy: 0.9816 - val_loss: 0.5152 - val_accuracy: 0.8205\n",
      "Epoch 2227/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0802 - accuracy: 0.9609 - val_loss: 0.5066 - val_accuracy: 0.8718\n",
      "Epoch 2228/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0754 - accuracy: 0.9575 - val_loss: 0.5231 - val_accuracy: 0.8462\n",
      "Epoch 2229/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0575 - accuracy: 0.9758 - val_loss: 0.3380 - val_accuracy: 0.8974\n",
      "Epoch 2230/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0323 - accuracy: 0.9873 - val_loss: 0.4313 - val_accuracy: 0.8718\n",
      "Epoch 2231/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0681 - accuracy: 0.9796 - val_loss: 0.4135 - val_accuracy: 0.8974\n",
      "Epoch 2232/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0547 - accuracy: 0.9785 - val_loss: 0.5215 - val_accuracy: 0.8205\n",
      "Epoch 2233/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.1010 - accuracy: 0.9569 - val_loss: 0.4350 - val_accuracy: 0.8718\n",
      "Epoch 2234/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0915 - accuracy: 0.9756 - val_loss: 0.4082 - val_accuracy: 0.8974\n",
      "Epoch 2235/10000\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.1032 - accuracy: 0.9617 - val_loss: 0.4060 - val_accuracy: 0.8974\n",
      "Epoch 2236/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0962 - accuracy: 0.9682 - val_loss: 0.2480 - val_accuracy: 0.9487\n",
      "Epoch 2237/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0642 - accuracy: 0.9756 - val_loss: 0.2046 - val_accuracy: 0.9487\n",
      "Epoch 2238/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0688 - accuracy: 0.9767 - val_loss: 0.3196 - val_accuracy: 0.9231\n",
      "Epoch 2239/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0644 - accuracy: 0.9789 - val_loss: 0.1950 - val_accuracy: 0.9231\n",
      "Epoch 2240/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0499 - accuracy: 0.9791 - val_loss: 0.3481 - val_accuracy: 0.8718\n",
      "Epoch 2241/10000\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0426 - accuracy: 0.9811 - val_loss: 0.2935 - val_accuracy: 0.8974\n",
      "Epoch 2242/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0225 - accuracy: 0.9955 - val_loss: 0.3050 - val_accuracy: 0.8718\n",
      "Epoch 2243/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0573 - accuracy: 0.9746 - val_loss: 0.5534 - val_accuracy: 0.8974\n",
      "Epoch 2244/10000\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.1179 - accuracy: 0.9516 - val_loss: 0.8677 - val_accuracy: 0.7692\n",
      "Epoch 2245/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.2316 - accuracy: 0.8943 - val_loss: 0.2764 - val_accuracy: 0.9231\n",
      "Epoch 2246/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.1879 - accuracy: 0.9256 - val_loss: 0.1311 - val_accuracy: 0.9487\n",
      "Epoch 2247/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.1131 - accuracy: 0.9684 - val_loss: 0.5846 - val_accuracy: 0.8205\n",
      "Epoch 2248/10000\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.1784 - accuracy: 0.9264 - val_loss: 0.2957 - val_accuracy: 0.8718\n",
      "Epoch 2249/10000\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.1136 - accuracy: 0.9516 - val_loss: 0.4946 - val_accuracy: 0.8974\n",
      "Epoch 2250/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0617 - accuracy: 0.9836 - val_loss: 0.7481 - val_accuracy: 0.8462\n",
      "Epoch 2251/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0684 - accuracy: 0.9706 - val_loss: 0.5971 - val_accuracy: 0.8974\n",
      "Epoch 2252/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0610 - accuracy: 0.9762 - val_loss: 0.5308 - val_accuracy: 0.8462\n",
      "Epoch 2253/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0833 - accuracy: 0.9751 - val_loss: 0.5132 - val_accuracy: 0.8718\n",
      "Epoch 2254/10000\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0761 - accuracy: 0.9674 - val_loss: 0.5620 - val_accuracy: 0.8718\n",
      "Epoch 2255/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0976 - accuracy: 0.9735 - val_loss: 0.4713 - val_accuracy: 0.8462\n",
      "Epoch 2256/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0477 - accuracy: 0.9811 - val_loss: 0.4023 - val_accuracy: 0.8718\n",
      "Epoch 2257/10000\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.0628 - accuracy: 0.9683 - val_loss: 0.2881 - val_accuracy: 0.8974\n",
      "Epoch 2258/10000\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.0593 - accuracy: 0.9793 - val_loss: 0.3208 - val_accuracy: 0.8718\n",
      "Epoch 2259/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0660 - accuracy: 0.9743 - val_loss: 0.3480 - val_accuracy: 0.8974\n",
      "Epoch 2260/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0586 - accuracy: 0.9687 - val_loss: 0.4676 - val_accuracy: 0.8205\n",
      "Epoch 2261/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0764 - accuracy: 0.9635 - val_loss: 0.4260 - val_accuracy: 0.9231\n",
      "Epoch 2262/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0675 - accuracy: 0.9690 - val_loss: 0.3406 - val_accuracy: 0.8974\n",
      "Epoch 2263/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0394 - accuracy: 0.9847 - val_loss: 0.6929 - val_accuracy: 0.8462\n",
      "Epoch 2264/10000\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0312 - accuracy: 0.9939 - val_loss: 0.2397 - val_accuracy: 0.9231\n",
      "Epoch 2265/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0520 - accuracy: 0.9744 - val_loss: 0.3312 - val_accuracy: 0.8974\n",
      "Epoch 2266/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0304 - accuracy: 0.9895 - val_loss: 0.3359 - val_accuracy: 0.8718\n",
      "Epoch 2267/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0691 - accuracy: 0.9657 - val_loss: 0.1414 - val_accuracy: 0.9487\n",
      "Epoch 2268/10000\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0406 - accuracy: 0.9915 - val_loss: 0.1556 - val_accuracy: 0.9487\n",
      "Epoch 2269/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.1130 - accuracy: 0.9453 - val_loss: 0.6906 - val_accuracy: 0.8462\n",
      "Epoch 2270/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.1245 - accuracy: 0.9573 - val_loss: 0.2962 - val_accuracy: 0.8718\n",
      "Epoch 2271/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0918 - accuracy: 0.9668 - val_loss: 0.2503 - val_accuracy: 0.8974\n",
      "Epoch 2272/10000\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0485 - accuracy: 0.9831 - val_loss: 0.2261 - val_accuracy: 0.8974\n",
      "Epoch 2273/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.1249 - accuracy: 0.9425 - val_loss: 0.2727 - val_accuracy: 0.9487\n",
      "Epoch 2274/10000\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0386 - accuracy: 0.9887 - val_loss: 0.4180 - val_accuracy: 0.8974\n",
      "Epoch 2275/10000\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.0538 - accuracy: 0.9793 - val_loss: 0.2704 - val_accuracy: 0.8718\n",
      "Epoch 2276/10000\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0540 - accuracy: 0.9860 - val_loss: 0.3856 - val_accuracy: 0.8974\n",
      "Epoch 2277/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0664 - accuracy: 0.9605 - val_loss: 0.2823 - val_accuracy: 0.9231\n",
      "Epoch 2278/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0642 - accuracy: 0.9764 - val_loss: 0.4026 - val_accuracy: 0.8974\n",
      "Epoch 2279/10000\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.2257 - accuracy: 0.9117 - val_loss: 0.5228 - val_accuracy: 0.7949\n",
      "Epoch 2280/10000\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.1254 - accuracy: 0.9497 - val_loss: 0.3203 - val_accuracy: 0.8462\n",
      "Epoch 2281/10000\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0707 - accuracy: 0.9762 - val_loss: 0.3180 - val_accuracy: 0.9231\n",
      "Epoch 2282/10000\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.1258 - accuracy: 0.9460 - val_loss: 0.4526 - val_accuracy: 0.8462\n",
      "Epoch 2283/10000\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.1673 - accuracy: 0.9523 - val_loss: 0.5866 - val_accuracy: 0.9231\n",
      "Epoch 2284/10000\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0909 - accuracy: 0.9728 - val_loss: 0.4214 - val_accuracy: 0.8974\n",
      "Epoch 2285/10000\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.0726 - accuracy: 0.9793 - val_loss: 0.2587 - val_accuracy: 0.9487\n",
      "Epoch 2286/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0665 - accuracy: 0.9695 - val_loss: 0.5824 - val_accuracy: 0.8462\n",
      "Epoch 2287/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.2042 - accuracy: 0.9245 - val_loss: 0.2751 - val_accuracy: 0.8974\n",
      "Epoch 2288/10000\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.1221 - accuracy: 0.9300 - val_loss: 0.7796 - val_accuracy: 0.8462\n",
      "Epoch 2289/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.1059 - accuracy: 0.9793 - val_loss: 0.6689 - val_accuracy: 0.8718\n",
      "Epoch 2290/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.1163 - accuracy: 0.9608 - val_loss: 0.6066 - val_accuracy: 0.8205\n",
      "Epoch 2291/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.1685 - accuracy: 0.9370 - val_loss: 0.5846 - val_accuracy: 0.8974\n",
      "Epoch 2292/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.1462 - accuracy: 0.9590 - val_loss: 0.5244 - val_accuracy: 0.8205\n",
      "Epoch 2293/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.1218 - accuracy: 0.9569 - val_loss: 0.2822 - val_accuracy: 0.8718\n",
      "Epoch 2294/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.1143 - accuracy: 0.9416 - val_loss: 0.2714 - val_accuracy: 0.9231\n",
      "Epoch 2295/10000\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0671 - accuracy: 0.9729 - val_loss: 0.4847 - val_accuracy: 0.8974\n",
      "Epoch 2296/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0654 - accuracy: 0.9710 - val_loss: 0.3988 - val_accuracy: 0.8974\n",
      "Epoch 2297/10000\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.0806 - accuracy: 0.9729 - val_loss: 0.4416 - val_accuracy: 0.8718\n",
      "Epoch 2298/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0890 - accuracy: 0.9569 - val_loss: 0.4096 - val_accuracy: 0.8718\n",
      "Epoch 2299/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0848 - accuracy: 0.9737 - val_loss: 0.3267 - val_accuracy: 0.8974\n",
      "Epoch 2300/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.1211 - accuracy: 0.9657 - val_loss: 0.4724 - val_accuracy: 0.8718\n",
      "Epoch 2301/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0649 - accuracy: 0.9628 - val_loss: 0.3104 - val_accuracy: 0.8462\n",
      "Epoch 2302/10000\n",
      "12/12 [==============================] - 1s 44ms/step - loss: 0.0647 - accuracy: 0.9812 - val_loss: 0.1048 - val_accuracy: 0.9231\n",
      "Epoch 2303/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0836 - accuracy: 0.9711 - val_loss: 0.3684 - val_accuracy: 0.9231\n",
      "Epoch 2304/10000\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0974 - accuracy: 0.9690 - val_loss: 0.3088 - val_accuracy: 0.9231\n",
      "Epoch 2305/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0566 - accuracy: 0.9798 - val_loss: 0.2732 - val_accuracy: 0.9231\n",
      "Epoch 2306/10000\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0545 - accuracy: 0.9737 - val_loss: 0.2748 - val_accuracy: 0.9487\n",
      "Epoch 2307/10000\n",
      "12/12 [==============================] - 1s 42ms/step - loss: 0.0591 - accuracy: 0.9782 - val_loss: 0.2758 - val_accuracy: 0.8974\n",
      "Epoch 2308/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0439 - accuracy: 0.9854 - val_loss: 0.1574 - val_accuracy: 0.9487\n",
      "Epoch 2309/10000\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0361 - accuracy: 0.9873 - val_loss: 0.3149 - val_accuracy: 0.8974\n",
      "Epoch 2310/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0985 - accuracy: 0.9598 - val_loss: 0.5760 - val_accuracy: 0.8718\n",
      "Epoch 2311/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0780 - accuracy: 0.9627 - val_loss: 0.4649 - val_accuracy: 0.8718\n",
      "Epoch 2312/10000\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.0679 - accuracy: 0.9761 - val_loss: 0.3203 - val_accuracy: 0.8205\n",
      "Epoch 2313/10000\n",
      "12/12 [==============================] - 1s 45ms/step - loss: 0.0988 - accuracy: 0.9664 - val_loss: 0.5197 - val_accuracy: 0.8205\n",
      "Epoch 2314/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.1039 - accuracy: 0.9696 - val_loss: 0.8738 - val_accuracy: 0.6667\n",
      "Epoch 2315/10000\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0958 - accuracy: 0.9684 - val_loss: 0.4885 - val_accuracy: 0.8462\n",
      "Epoch 02315: early stopping\n"
     ]
    }
   ],
   "source": [
    "wandb.init(\n",
    "    project=\"physiotherapy-platform\",\n",
    "    config={\"MobileNetv2_alpha\": 0.3}\n",
    ")\n",
    "\n",
    "model = MobileNetV2(\n",
    "    input_shape=IMAGE_SHAPE,\n",
    "    alpha=wandb.config.MobileNetv2_alpha,\n",
    "    classes=NUMBER_OF_CLASSES,\n",
    "    weights=None\n",
    ")\n",
    "\n",
    "optimizer = Adam()\n",
    "earlystop = EarlyStopping(monitor='loss', patience=300, verbose=2, mode='min')\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    validation_data=validation_generator,\n",
    "                    steps_per_epoch=None,\n",
    "                    validation_steps=None,\n",
    "                    epochs=MAX_EPOCHS,\n",
    "                    callbacks=[earlystop, WandbCallback()])\n"
   ]
  },
  {
   "source": [
    "Saves the model and converts it to TF-Lite."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: model/saved/assets\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpichc3vug/assets\n",
      "INFO:tensorflow:Assets written to: /tf/wandb/run-20210107_232438-1dfwiqm1/files/SavedModel/assets\n",
      "INFO:tensorflow:Assets written to: /tf/wandb/run-20210107_232438-1dfwiqm1/files/SavedModel/assets\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('model', exist_ok=True)\n",
    "\n",
    "df = pd.DataFrame.from_dict(history.history)\n",
    "df.to_csv('model/history.csv', encoding='utf-8', index=False)\n",
    "model.save('model/model.h5')\n",
    "model.save('model/saved')\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TF Lite model.\n",
    "with tf.io.gfile.GFile('model/model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "with tf.io.gfile.GFile(os.path.join(wandb.run.dir, 'model.tflite'), 'wb') as f:\n",
    "    f.write(tflite_model)\n",
    "\n",
    "model.save(os.path.join(wandb.run.dir, \"model.h5\"))\n",
    "model.save(os.path.join(wandb.run.dir, \"SavedModel\"))"
   ]
  }
 ]
}